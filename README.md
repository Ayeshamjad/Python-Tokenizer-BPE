# Python-Tokenizer-BPE

A custom tokenizer for Python code using **Byte Pair Encoding (BPE)**, trained on 11M+ code samples from the [PhyloToAST](https://github.com/smdabdoub/phylotoast) GitHub repository. The tokenizer is evaluated against **Unigram**, **WordPiece**, and **Whole-Word Lexical Categorization (WLC)** methods.

---

## ðŸ“Œ Highlights

- **Dataset:** 11,032,441 Python files (functions, loops, comments, etc.)
- **Tokenization Method:** BPE (subword-based, compact vocabulary)
- **Comparisons:** Unigram, WordPiece, WLC
- **Vocabulary Size:** 30,000  
- **OOV Rate:** 7%  
- **Avg Tokens/Sentence:** 9.3  


